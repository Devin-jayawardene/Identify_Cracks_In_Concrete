{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,input_tensor=Input(shape=(224,224, 3)))\n",
    "\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(4, 4))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
    "\n",
    "\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "for layer in baseModel.layers:\n",
    "    \n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam',metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weights-026.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test_data=np.load('test_data_unscaled.npy')\n",
    "test_target=np.load('test_target.npy')\n",
    "test_data_scaled=test_data/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 6s 587ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "[0.004282616078853607, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(test_data_scaled,test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "category_dict={0:'Negative',1:'Positive'}\n",
    "\n",
    "for img in test_data:\n",
    "    \n",
    "    h,w=img.shape[0:2]\n",
    "\n",
    "    \n",
    "    scaled_img=img/255\n",
    "    scaled_img=scaled_img.reshape(1,img.shape[0],img.shape[1],img.shape[2])\n",
    "    \n",
    "    results=model.predict(scaled_img)\n",
    "    label=np.argmax(results,axis=1)[0]\n",
    "    acc=int(np.max(results,axis=1)[0]*100)\n",
    "    \n",
    "    \n",
    "    img[0:50,0:w]=[0,255,0]\n",
    "    cv2.putText(img,category_dict[label],(20,40),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2)\n",
    "    cv2.putText(img,str(acc)+'%',(170,40),cv2.FONT_HERSHEY_PLAIN,1,(255,255,255),2)\n",
    "    \n",
    "    cv2.imshow('LIVE',img)\n",
    "    k=cv2.waitKey(1000)\n",
    "    if(k==27):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
